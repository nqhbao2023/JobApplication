# ğŸ”„ Giáº£i ThÃ­ch Flow Crawl Job tá»« Viecoi.vn

## âš ï¸ LÆ°u Ã Quan Trá»ng

**Viecoi.vn sá»­ dá»¥ng Cloudflare Bot Protection!** 

Website viecoi.vn Ä‘Æ°á»£c báº£o vá»‡ bá»Ÿi Cloudflare vÃ  cháº·n:
- âŒ Requests tá»« datacenter IPs (GitHub Actions)
- âŒ Requests tá»« axios/cheerio (khÃ´ng cÃ³ browser)
- âœ… **Puppeteer vá»›i real browser** - bypass Ä‘Æ°á»£c Cloudflare! ğŸ‰

### ğŸš€ Cháº¡y Crawler Tá»« MÃ¡y Local (Puppeteer - KHUYÃŠN DÃ™NG)

```powershell
cd server

# CÃ¡ch 1: Full pipeline (Crawl + AI Categorize + Normalize + Upsert + Sync Algolia)
npm run crawl:viecoi-full -- --limit 50

# CÃ¡ch 2: Chá»‰ crawl dá»¯ liá»‡u thÃ´ (khÃ´ng cáº§n Firebase)
npm run crawl:viecoi-puppeteer -- --limit 50

# CÃ¡ch 3: Cháº¡y pipeline tá»« dá»¯ liá»‡u Ä‘Ã£ crawl (skip crawl step)
npx ts-node src/crawlers/viecoi/puppeteer-full-pipeline.ts --skip-crawl
```

### ğŸ“Š Káº¿t Quáº£ Thá»±c Táº¿

- **Success rate:** 100% (Puppeteer bypass Cloudflare thÃ nh cÃ´ng)
- **Dá»¯ liá»‡u:** JSON-LD structured data (schema.org/JobPosting)
- **Fallback:** DOM selectors náº¿u khÃ´ng cÃ³ JSON-LD
- **AI Categorization:** Hybrid (Regex 80% + Gemini AI 20%)

---

## ğŸ†• NEW: Hybrid AI Categorization System

### Giá»›i Thiá»‡u
Há»‡ thá»‘ng phÃ¢n loáº¡i cÃ´ng viá»‡c thÃ´ng minh 2 lá»›p:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYBRID AI CATEGORIZATION                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Layer 1: REGEX PATTERNS (Fast, ~80% jobs)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Confidence scoring vá»›i weighted patterns           â”‚     â”‚
â”‚  â”‚ â€¢ ~50 regex patterns cho 15 categories               â”‚     â”‚
â”‚  â”‚ â€¢ Threshold: â‰¥60% confidence â†’ use regex result      â”‚     â”‚
â”‚  â”‚ â€¢ Xá»­ lÃ½: <10ms/job                                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                    â”‚
â”‚                           â”‚ confidence < 60%                   â”‚
â”‚                           â–¼                                    â”‚
â”‚  Layer 2: GEMINI AI BATCH (~20% jobs)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ â€¢ Batch processing: 5 jobs/request                   â”‚     â”‚
â”‚  â”‚ â€¢ Smart prompts vá»›i context                          â”‚     â”‚
â”‚  â”‚ â€¢ Fallback to "other" náº¿u AI error                   â”‚     â”‚
â”‚  â”‚ â€¢ Rate limiting: 500ms giá»¯a cÃ¡c batch                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Categories Supported (15 loáº¡i)
| ID | Category | Patterns Examples |
|----|----------|-------------------|
| `it-software` | IT/Software | developer, react, python, devops |
| `marketing` | Marketing | seo, content, social media |
| `sales` | Sales | bÃ¡n hÃ ng, kinh doanh, telesales |
| `design` | Design | ui/ux, photoshop, graphic |
| `finance` | Finance | káº¿ toÃ¡n, tÃ i chÃ­nh, ngÃ¢n hÃ ng |
| `hr` | HR/Admin | nhÃ¢n sá»±, tuyá»ƒn dá»¥ng, hÃ nh chÃ­nh |
| `engineering` | Engineering | ká»¹ sÆ°, cÆ¡ khÃ­, Ä‘iá»‡n tá»­ |
| `healthcare` | Healthcare | bÃ¡c sÄ©, y tÃ¡, dÆ°á»£c |
| `education` | Education | giÃ¡o viÃªn, gia sÆ°, Ä‘Ã o táº¡o |
| `f&b` | F&B | nhÃ  hÃ ng, bartender, báº¿p |
| `retail` | Retail | bÃ¡n láº», thu ngÃ¢n, cá»­a hÃ ng |
| `logistics` | Logistics | kho, váº­n chuyá»ƒn, xuáº¥t nháº­p kháº©u |
| `construction` | Construction | xÃ¢y dá»±ng, cÃ´ng trÃ¬nh |
| `manufacturing` | Manufacturing | sáº£n xuáº¥t, nhÃ  mÃ¡y |
| `other` | Other | fallback category |

### Files Structure
```
server/src/crawlers/viecoi/
â”œâ”€â”€ ai-categorizer.ts          # ğŸ†• Hybrid AI categorization service
â”œâ”€â”€ puppeteer-full-pipeline.ts # Updated: integrated AI categorization
â””â”€â”€ ...

server/data/logs/
â”œâ”€â”€ categorization.log         # AI categorization detailed logs
â””â”€â”€ pipeline.log               # Pipeline execution logs
```

### Sample Output
```json
{
  "title": "Senior React Developer",
  "company_name": "TechCorp",
  "jobCategories": "it-software",
  "categoryConfidence": 95,
  "categoryMethod": "regex",
  ...
}
```

---

## ğŸ¤– Auto Scheduling (Windows Task Scheduler)

### Giá»›i Thiá»‡u
Tá»± Ä‘á»™ng cháº¡y crawler má»—i 6 giá» vá»›i PowerShell script.

### Files
```
JobApplication/
â”œâ”€â”€ auto-crawl.ps1             # ğŸ†• PowerShell auto-run script
â””â”€â”€ server/data/logs/
    â”œâ”€â”€ auto-crawl.log         # Auto-run execution logs
    â”œâ”€â”€ categorization.log     # AI categorization logs
    â””â”€â”€ pipeline.log           # Pipeline logs
```

### CÃ i Äáº·t Task Scheduler (Windows)

#### CÃ¡ch 1: GUI (Task Scheduler)

1. Má»Ÿ **Task Scheduler** (Win + R â†’ `taskschd.msc`)
2. Click **Create Basic Task...**
3. Äiá»n thÃ´ng tin:
   - **Name:** `Job4S Auto Crawler`
   - **Description:** `Automatically crawl jobs from viecoi.vn every 6 hours`
4. **Trigger:** Daily, repeat every 6 hours
   - Start: chá»n thá»i gian báº¯t Ä‘áº§u
   - Repeat task every: `6 hours`
   - For a duration of: `Indefinitely`
5. **Action:** Start a program
   - Program: `powershell.exe`
   - Arguments: `-ExecutionPolicy Bypass -File "C:\Users\Admin\Documents\GitHub\JobApplication\auto-crawl.ps1" -Limit 50`
6. **Conditions:** 
   - â˜ Start only if computer is on AC power (uncheck)
   - â˜‘ Wake the computer to run this task (optional)
7. **Settings:**
   - â˜‘ Run task as soon as possible after a scheduled start is missed
   - â˜ Stop the task if it runs longer than: (uncheck or set 1 hour)

#### CÃ¡ch 2: Command Line (schtasks)

```powershell
# Táº¡o task cháº¡y má»—i 6 giá»
schtasks /create `
  /tn "Job4S_AutoCrawler" `
  /tr "powershell.exe -ExecutionPolicy Bypass -File 'C:\Users\Admin\Documents\GitHub\JobApplication\auto-crawl.ps1' -Limit 50" `
  /sc DAILY /st 00:00 `
  /ri 360 `
  /du 24:00 `
  /f

# Kiá»ƒm tra task Ä‘Ã£ táº¡o
schtasks /query /tn "Job4S_AutoCrawler"

# Cháº¡y thá»§ cÃ´ng Ä‘á»ƒ test
schtasks /run /tn "Job4S_AutoCrawler"

# XÃ³a task
schtasks /delete /tn "Job4S_AutoCrawler" /f
```

### Script Options

```powershell
# Cháº¡y vá»›i default settings (50 jobs)
.\auto-crawl.ps1

# Crawl nhiá»u jobs hÆ¡n
.\auto-crawl.ps1 -Limit 100

# Skip crawl, chá»‰ process data cÃ³ sáºµn
.\auto-crawl.ps1 -SkipCrawl

# Gá»­i email notification (cáº§n config SMTP_USER, SMTP_PASS)
.\auto-crawl.ps1 -SendEmail -EmailTo "admin@example.com"

# Verbose mode
.\auto-crawl.ps1 -Verbose
```

### Email Notification Setup (Optional)

Äá»ƒ nháº­n email thÃ´ng bÃ¡o sau má»—i láº§n crawl:

1. Táº¡o Gmail App Password:
   - VÃ o https://myaccount.google.com/apppasswords
   - Táº¡o app password má»›i
   
2. Set environment variables:
```powershell
[System.Environment]::SetEnvironmentVariable("SMTP_USER", "your-email@gmail.com", "User")
[System.Environment]::SetEnvironmentVariable("SMTP_PASS", "your-app-password", "User")
```

3. Cháº¡y vá»›i `-SendEmail`:
```powershell
.\auto-crawl.ps1 -Limit 50 -SendEmail -EmailTo "admin@yourcompany.com"
```

### Logs

Táº¥t cáº£ logs Ä‘Æ°á»£c lÆ°u trong `server/data/logs/`:

```
logs/
â”œâ”€â”€ auto-crawl.log       # Script execution logs
â”œâ”€â”€ pipeline.log         # Pipeline details
â””â”€â”€ categorization.log   # AI categorization stats
```

#### Sample Log Output:
```
[2024-12-01 06:00:01] [INFO] ============================================================
[2024-12-01 06:00:01] [INFO] Job4S Auto Crawler - 2024-12-01 06:00:01
[2024-12-01 06:00:01] [INFO] ============================================================
[2024-12-01 06:00:02] [INFO] Checking environment...
[2024-12-01 06:00:02] [INFO] Node.js version: v20.10.0
[2024-12-01 06:00:02] [INFO] npm version: 10.2.3
[2024-12-01 06:00:03] [INFO] Running pipeline command...
...
[2024-12-01 06:05:30] [INFO] Total jobs: 48
[2024-12-01 06:05:30] [INFO] Regex Categorized: 40
[2024-12-01 06:05:30] [INFO] AI Categorized: 8
[2024-12-01 06:05:30] [SUCCESS] Pipeline completed successfully!
```

---

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng tá»± Ä‘á»™ng crawl (thu tháº­p) tin tuyá»ƒn dá»¥ng tá»« website **viecoi.vn**, chuáº©n hÃ³a dá»¯ liá»‡u, lÆ°u vÃ o **Firebase Firestore**, vÃ  Ä‘á»“ng bá»™ lÃªn **Algolia** Ä‘á»ƒ tÃ¬m kiáº¿m nhanh.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Viecoi.vn  â”‚ -> â”‚   Crawl     â”‚ -> â”‚  Normalize  â”‚ -> â”‚  Firestore  â”‚ -> â”‚   Algolia   â”‚
â”‚  (Website)  â”‚    â”‚  (Raw Data) â”‚    â”‚  (Clean)    â”‚    â”‚  (Database) â”‚    â”‚  (Search)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Cáº¥u TrÃºc Files

```
server/
â”œâ”€â”€ src/crawlers/viecoi/
â”‚   â”œâ”€â”€ ai-categorizer.ts         # ğŸ†• Hybrid AI categorization (Regex + Gemini)
â”‚   â”œâ”€â”€ puppeteer-crawler.ts      # Crawl báº±ng Puppeteer (bypass Cloudflare)
â”‚   â”œâ”€â”€ puppeteer-full-pipeline.ts # Full pipeline: crawl â†’ AI categorize â†’ upsert â†’ sync
â”‚   â”œâ”€â”€ upsert-jobs.ts            # LÆ°u vÃ o Firebase Firestore
â”‚   â””â”€â”€ sync-algolia.ts           # Äá»“ng bá»™ lÃªn Algolia Search
â”‚   â”‚
â”‚   â”‚ # Backup (trong thÆ° má»¥c TEMP)
â”‚   â””â”€â”€ ../TEMP/
â”‚       â”œâ”€â”€ normalizer.ts         # Old normalizer (backup)
â”‚       â””â”€â”€ normalize-runner.ts   # Old runner (backup)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ viecoi/
â”‚   â”‚   â”œâ”€â”€ raw-jobs.json         # Output crawl (dá»¯ liá»‡u thÃ´ tá»« JSON-LD)
â”‚   â”‚   â””â”€â”€ normalized-jobs.json  # Output normalize (Ä‘Ã£ chuáº©n hÃ³a + AI categorized)
â”‚   â””â”€â”€ logs/
â”‚       â”œâ”€â”€ categorization.log    # AI categorization detailed logs
â”‚       â”œâ”€â”€ pipeline.log          # Pipeline execution logs
â”‚       â””â”€â”€ auto-crawl.log        # Auto scheduler logs
â”‚
â””â”€â”€ package.json                  # Äá»‹nh nghÄ©a cÃ¡c npm scripts

# Root level
JobApplication/
â””â”€â”€ auto-crawl.ps1                # ğŸ†• PowerShell auto scheduler script
```

---

## ğŸ“ Chi Tiáº¿t Tá»«ng BÆ°á»›c (Puppeteer - Má»›i)

### **BÆ°á»›c 1: Crawl URLs tá»« Trang Listing**
ğŸ“„ **File:** `server/src/crawlers/viecoi/puppeteer-crawler.ts`

```typescript
// DÃ¹ng Puppeteer Ä‘á»ƒ load trang nhÆ° browser tháº­t
async function fetchJobURLsFromListing() {
  const browser = await puppeteer.launch({ headless: 'new' });
  const page = await browser.newPage();
  
  // Navigate to listing page (Cloudflare bypass!)
  await page.goto('https://viecoi.vn/viec-lam', { waitUntil: 'networkidle2' });
  
  // Extract all job URLs from page
  const urls = await page.$$eval('a[href*="/viec-lam/"]', links =>
    links.map(a => a.href).filter(href => /\/viec-lam\/.*\.html$/.test(href))
  );
  
  return urls;
}
```

**Chá»©c nÄƒng:**
- Puppeteer má»Ÿ browser tháº­t (Chromium)
- Bypass Cloudflare protection 
- Láº¥y danh sÃ¡ch URLs tá»« trang listing

---

### **BÆ°á»›c 2: Extract Job Detail tá»« JSON-LD**
ğŸ“„ **File:** `server/src/crawlers/viecoi/puppeteer-crawler.ts`

```typescript
// Extract JSON-LD structured data (schema.org/JobPosting)
async function extractJobDetail(page: Page): Promise<RawJob | null> {
  // 1. TÃ¬m JSON-LD trong trang
  const jsonLd = await page.$eval(
    'script[type="application/ld+json"]',
    el => JSON.parse(el.textContent || '{}')
  );
  
  // 2. Parse JobPosting schema
  if (jsonLd['@type'] === 'JobPosting') {
    return {
      title: jsonLd.title,
      company: jsonLd.hiringOrganization?.name,
      salary_min: jsonLd.baseSalary?.value?.minValue,
      salary_max: jsonLd.baseSalary?.value?.maxValue,
      location: jsonLd.jobLocation?.address?.addressLocality,
      description: jsonLd.description,
      employmentType: jsonLd.employmentType,
      // ...
    };
  }
  
  // 3. Fallback: DOM selectors náº¿u khÃ´ng cÃ³ JSON-LD
  return extractFromDOM(page);
}
```

**Output máº«u (raw tá»« JSON-LD):**
```json
{
  "url": "https://viecoi.vn/viec-lam/nhan-vien-ke-toan-119163.html",
  "title": "NHÃ‚N VIÃŠN Káº¾ TOÃN",
  "company": "CÃ´ng ty ABC",
  "salary_min": 10000000,
  "salary_max": 15000000,
  "location": "Há»“ ChÃ­ Minh",
  "employmentType": "FULL_TIME",
  "category": "Káº¿ toÃ¡n - Kiá»ƒm toÃ¡n"
}
```

---

### **BÆ°á»›c 3: Chuáº©n HÃ³a Dá»¯ Liá»‡u**
ğŸ“„ **File:** `server/src/crawlers/viecoi/normalizer.ts`

```typescript
// Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ´ â†’ format chuáº©n cá»§a app
export function normalizeJob(job: JobData): NormalizedJob {
  return {
    title: job.title,
    company_name: job.company,
    salary_min: parseSalary(job.salary).min,  // "10-15 triá»‡u" â†’ 10000000
    salary_max: parseSalary(job.salary).max,  // "10-15 triá»‡u" â†’ 15000000
    salary_text: job.salary,
    job_type_id: normalizeJobType(job.jobType), // "Full-time" â†’ "full-time"
    jobCategories: normalizeCategory(job.category), // "Káº¿ toÃ¡n" â†’ "finance"
    source: 'viecoi',
    status: 'pending',
    // ...
  };
}
```

**Chá»©c nÄƒng:**
- **Parse salary:** "10-15 triá»‡u" â†’ `{ min: 10000000, max: 15000000 }`
- **Map job type:** "ToÃ n thá»i gian" â†’ `"full-time"` (khá»›p vá»›i Firestore)
- **Map category:** "CÃ´ng nghá»‡ thÃ´ng tin" â†’ `"it-software"`
- **Deduplicate:** Loáº¡i bá» jobs trÃ¹ng láº·p
- LÆ°u káº¿t quáº£ vÃ o `data/viecoi/normalized-jobs.json`

**Output máº«u (normalized):**
```json
{
  "title": "NHÃ‚N VIÃŠN Káº¾ TOÃN",
  "company_name": "CÃ´ng ty ABC",
  "salary_min": 10000000,
  "salary_max": 15000000,
  "salary_text": "10 - 15 triá»‡u",
  "job_type_id": "full-time",        // â† ID khá»›p vá»›i collection job_types
  "jobCategories": "finance",         // â† ID khá»›p vá»›i collection job_categories
  "source": "viecoi",
  "status": "pending",
  "external_url": "https://viecoi.vn/..."
}
```

---

### **BÆ°á»›c 4: LÆ°u VÃ o Firestore**
ğŸ“„ **File:** `server/src/crawlers/viecoi/upsert-jobs.ts`

```typescript
// Upsert = Update náº¿u tá»“n táº¡i, Insert náº¿u chÆ°a cÃ³
async function upsertJob(job: any) {
  // Kiá»ƒm tra job Ä‘Ã£ tá»“n táº¡i chÆ°a (theo external_url)
  const existing = await jobsRef
    .where('external_url', '==', job.external_url)
    .get();

  if (!existing.empty) {
    // ÄÃ£ cÃ³ â†’ Update
    await jobsRef.doc(existing.docs[0].id).update(job);
  } else {
    // ChÆ°a cÃ³ â†’ Insert má»›i
    await jobsRef.add(job);
  }
}
```

**Chá»©c nÄƒng:**
- Káº¿t ná»‘i Firebase Admin SDK
- Kiá»ƒm tra job Ä‘Ã£ tá»“n táº¡i chÆ°a (trÃ¡nh duplicate)
- Tá»± Ä‘á»™ng táº¡o Company náº¿u chÆ°a cÃ³
- Insert/Update jobs vÃ o collection `jobs`

---

### **BÆ°á»›c 5: Äá»“ng Bá»™ LÃªn Algolia**
ğŸ“„ **File:** `server/src/crawlers/viecoi/sync-algolia.ts`

```typescript
// Láº¥y jobs tá»« Firestore vÃ  Ä‘áº©y lÃªn Algolia
async function syncToAlgolia(jobs: any[]) {
  const algoliaObjects = jobs.map(job => ({
    objectID: job.id,
    title: job.title,
    company_name: job.company_name,
    location: job.location,
    salary_text: job.salary_text,
    // ... cÃ¡c field cáº§n tÃ¬m kiáº¿m
  }));

  await client.saveObjects({
    indexName: 'jobs',
    objects: algoliaObjects,
  });
}
```

**Chá»©c nÄƒng:**
- Láº¥y jobs cÃ³ `source='viecoi'` tá»« Firestore
- Format láº¡i cho Algolia (cáº§n `objectID`)
- Push lÃªn Algolia index `jobs`
- Cho phÃ©p tÃ¬m kiáº¿m full-text nhanh trong app

---

## âš¡ GitHub Actions - ÄÃƒ DISABLED

> âš ï¸ **LÆ°u Ã½:** GitHub Actions Ä‘Ã£ bá»‹ disable vÃ¬ Cloudflare cháº·n datacenter IPs.
> Crawler chá»‰ cháº¡y Ä‘Æ°á»£c tá»« mÃ¡y local báº±ng Puppeteer.

ğŸ“„ **File:** `.github/workflows/auto-crawler.yml`

```yaml
# âš ï¸ DISABLED - Cloudflare blocks GitHub Actions IPs
# Viecoi.vn returns 403 Forbidden when accessed from datacenter IPs
# 
# Solution: Run crawler locally using Puppeteer
# Command: cd server && npm run crawl:viecoi-full -- --limit 50

on:
  # schedule:   # â† DISABLED
  #   - cron: '0 */6 * * *'
  workflow_dispatch:  # Váº«n cho phÃ©p trigger thá»§ cÃ´ng Ä‘á»ƒ test
```

**Thay tháº¿ báº±ng:** Cháº¡y thá»§ cÃ´ng tá»« mÃ¡y local vá»›i Puppeteer

---

## ğŸ”§ NPM Scripts (Puppeteer - Má»›i)

Trong `server/package.json`:

```json
{
  "scripts": {
    // ğŸ†• Puppeteer crawler (bypass Cloudflare)
    "crawl:viecoi-puppeteer": "npx ts-node src/crawlers/viecoi/puppeteer-crawler.ts",
    "crawl:viecoi-pipeline": "npx ts-node src/crawlers/viecoi/puppeteer-full-pipeline.ts",
    "crawl:viecoi-full": "npx ts-node src/crawlers/viecoi/puppeteer-crawler.ts && npx ts-node src/crawlers/viecoi/puppeteer-full-pipeline.ts",
    
    // CÃ¡c script riÃªng láº»
    "normalize:viecoi": "ts-node src/crawlers/viecoi/normalize-runner.ts",
    "upsert:viecoi-jobs": "ts-node src/crawlers/viecoi/upsert-jobs.ts",
    "sync:viecoi-algolia": "ts-node src/crawlers/viecoi/sync-algolia.ts"
  }
}
```

### Sá»­ Dá»¥ng:

```powershell
cd server

# 1. Crawl 50 jobs má»›i nháº¥t (bypass Cloudflare)
npm run crawl:viecoi-puppeteer -- --limit 50

# 2. Xá»­ lÃ½ pipeline (normalize â†’ upsert â†’ sync)
npm run crawl:viecoi-pipeline

# 3. Full pipeline (1 + 2 gá»™p láº¡i)
npm run crawl:viecoi-full -- --limit 50

# 4. Chá»‰ sync láº¡i Algolia (khÃ´ng cáº§n crawl láº¡i)
npm run sync:viecoi-algolia
```

---

## â“ FAQ - CÃ¢u Há»i ThÆ°á»ng Gáº·p

### **Q1: Dá»¯ liá»‡u cÃ³ tá»± Ä‘á»™ng sync lÃªn Algolia khÃ´ng?**
âœ… **CÃ“** - Khi cháº¡y `crawl:viecoi-full` hoáº·c `crawl:viecoi-pipeline`, Algolia sáº½ Ä‘Æ°á»£c sync tá»± Ä‘á»™ng

### **Q2: Dá»¯ liá»‡u cÃ³ tá»± chuáº©n hÃ³a khÃ´ng?**
âœ… **CÃ“** - Pipeline sáº½ tá»± Ä‘á»™ng:
- Parse salary tá»« JSON-LD â†’ sá»‘
- Map employment type â†’ ID chuáº©n (`full-time`, `part-time`,...)
- Map category â†’ ID chuáº©n (`it-software`, `marketing`,...)
- Loáº¡i bá» duplicates theo URL

### **Q3: Má»—i láº§n crawl bao nhiÃªu jobs?**
- **Máº·c Ä‘á»‹nh:** 50 jobs
- **CÃ³ thá»ƒ thay Ä‘á»•i:** `npm run crawl:viecoi-full -- --limit 100`

### **Q4: Jobs má»›i cÃ³ hiá»ƒn thá»‹ ngay trong app khÃ´ng?**
âš ï¸ **KHÃ”NG NGAY** - Jobs crawl cÃ³ `status: 'pending'`
- Cáº§n Admin duyá»‡t â†’ Ä‘á»•i thÃ nh `status: 'active'`
- Hoáº·c sá»­a code trong `upsert-jobs.ts` Ä‘á»ƒ set `status: 'active'` luÃ´n

### **Q5: Táº¡i sao filter Job Types khÃ´ng hoáº¡t Ä‘á»™ng?**
**ÄÃ£ fix!** Váº¥n Ä‘á» lÃ :
- Jobs tá»« viecoi lÆ°u `job_type_id: "full-time"` (string)
- Jobs táº¡o thá»§ cÃ´ng lÆ°u `jobTypes: { $id: "full-time" }` (object)
- Code filter Ä‘Ã£ Ä‘Æ°á»£c update Ä‘á»ƒ há»— trá»£ cáº£ 2 format

### **Q6: Crawler cÃ³ tá»‘n tiá»n khÃ´ng?**
âŒ **KHÃ”NG** - Puppeteer cháº¡y local, khÃ´ng tá»‘n chi phÃ­

### **Q7: Náº¿u viecoi.vn Ä‘á»•i giao diá»‡n thÃ¬ sao?**
âœ… **Ãt bá»‹ áº£nh hÆ°á»Ÿng** vÃ¬:
- Æ¯u tiÃªn JSON-LD structured data (schema.org) - ráº¥t á»•n Ä‘á»‹nh
- DOM selectors chá»‰ lÃ  fallback
- Náº¿u cáº§n sá»­a: update file `puppeteer-crawler.ts`

### **Q8: Táº¡i sao khÃ´ng dÃ¹ng GitHub Actions?**
âŒ Cloudflare cháº·n datacenter IPs cá»§a GitHub Actions
- Tráº£ vá» 403 Forbidden
- Puppeteer cáº§n cháº¡y tá»« residential IP (mÃ¡y local)

---

## ğŸ” Debug & Troubleshooting

### **Cháº¡y local Ä‘á»ƒ test:**
```powershell
cd server

# Test crawl 5 jobs
npm run crawl:viecoi-puppeteer -- --limit 5

# Test full pipeline
npm run crawl:viecoi-full -- --limit 10

# Chá»‰ cháº¡y pipeline (náº¿u Ä‘Ã£ cÃ³ raw data)
npm run crawl:viecoi-pipeline
```

### **Xem dá»¯ liá»‡u crawl:**
- Raw: `server/data/viecoi/raw-jobs.json`
- Normalized: `server/data/viecoi/normalized-jobs.json`

### **Debug JSON-LD:**
```powershell
# Xem JSON-LD cá»§a 1 trang job
# (Puppeteer crawler sáº½ tá»± Ä‘á»™ng log thÃ´ng tin debug)
npm run crawl:viecoi-puppeteer -- --limit 1
```

### **Kiá»ƒm tra Firestore:**
- VÃ o Firebase Console â†’ Firestore â†’ Collection `jobs`
- Filter: `source == 'viecoi'`

### **Kiá»ƒm tra Algolia:**
- VÃ o Algolia Dashboard â†’ Index `jobs`
- Search vá»›i filter: `source:viecoi`

---

## ğŸ“Š Luá»“ng Dá»¯ Liá»‡u Tá»•ng Quan (Puppeteer)

```
                         GitHub Actions (má»—i 6 giá»)
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CRAWL PIPELINE                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  sitemap    â”‚ --> â”‚  50 URLs    â”‚ --> â”‚  50 Raw Jobs    â”‚    â”‚
â”‚  â”‚  viecoi.vn  â”‚     â”‚  job pages  â”‚     â”‚  (JSON file)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                                          â”‚   Normalize     â”‚    â”‚
â”‚                                          â”‚   + Dedupe      â”‚    â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                                          â”‚  Normalized     â”‚    â”‚
â”‚                                          â”‚  Jobs (JSON)    â”‚    â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STORAGE                                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚    Firestore    â”‚    ------>   â”‚     Algolia     â”‚           â”‚
â”‚  â”‚  (jobs, etc.)   â”‚    sync      â”‚   (search)      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MOBILE APP                                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Job List   â”‚     â”‚   Search    â”‚     â”‚  Job Details    â”‚    â”‚
â”‚  â”‚  (Firestore)â”‚     â”‚  (Algolia)  â”‚     â”‚                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist Setup

- [x] Táº¡o GitHub Secrets (Firebase, Algolia credentials)
- [x] Node.js version 20 trong workflow
- [x] Fix job type filter trong app
- [x] XÃ³a workflow duplicate
- [x] ğŸ†• Hybrid AI Categorization (Regex + Gemini)
- [x] ğŸ†• Auto scheduler vá»›i Windows Task Scheduler
- [x] ğŸ†• Logging Ä‘áº§y Ä‘á»§ cho monitoring
- [ ] (TÃ¹y chá»n) Äá»•i `status: 'pending'` â†’ `'active'` Ä‘á»ƒ jobs hiá»‡n ngay
- [ ] (TÃ¹y chá»n) Setup email notification cho auto-crawl

---

## ğŸš€ Quick Start Guide

### 1. Cháº¡y manual crawler:
```powershell
cd server
npx ts-node src/crawlers/viecoi/puppeteer-full-pipeline.ts --limit 50
```

### 2. Setup auto scheduler:
```powershell
# Tá»« root folder JobApplication
.\auto-crawl.ps1 -Limit 50
```

### 3. Setup Task Scheduler (cháº¡y má»—i 6 giá»):
```powershell
schtasks /create /tn "Job4S_AutoCrawler" `
  /tr "powershell.exe -ExecutionPolicy Bypass -File 'C:\Users\Admin\Documents\GitHub\JobApplication\auto-crawl.ps1' -Limit 50" `
  /sc DAILY /st 00:00 /ri 360 /du 24:00 /f
```

### 4. Monitor logs:
```powershell
Get-Content server\data\logs\pipeline.log -Tail 50
Get-Content server\data\logs\categorization.log -Tail 50
```

---

*Cáº­p nháº­t: December 1, 2025*
